# https://blog.csdn.net/u010536377/article/details/50525785#%E7%A6%BB%E7%BE%A4%E7%82%B9%E6%A3%80%E6%B5%8B



基于K-means算法和LOF算法的CLOF算法:
在聚类过程中，将那些不属于任何簇的点作为离群点。然而，基于聚类的离群点检测方法主要目标是聚类，离群点只是聚类时产生的“副产物”。因此传统的基于聚类的离群点离群点检测方法检测精度比较低。
基于密度的LOF算法，能有效的检测数据集中的局部离群点和全局离群点，检测精度比较高。但是基于密度的LOF方法存在如下缺点，使其应用受到一定的限制。 
LOF方法在检测离群点的过程中，遍历整个数据集以计算每个点的LOF值，使得算法运算速度慢。同时，由于数据正常点的数量一般远远多于离群点的数量，而LOF方法通过比较所有数据点的LOF值判断离群程度，这产生了大量没必要的计算，造成时间成本太高，同时由于中间结果的存储而浪费空间资源。因此，假如能在计算离群因子前，剪枝一部分正常数据点，则可以提高LOF方法的计算效率。 
那么如何进行剪枝呢？考虑到K-means是一种效率很高的聚类的算法，CLOF算法利用了该聚类算法，对数据集进行剪枝，得到“离群点侯选集”，最后对该集合中的所有点执行LOF算法，从而判断是否是离群点。 
综上所述，CLOF算法的第一阶段是调用k均值聚类算法，聚完类后，可以得到k个类的中心（质点），然后求出类中所有点到该质点距离的平均值，这个平均值记为半径R，针对类中所有点，若该点到质点的距离大于等于R，则将其放入离群点候选集中。


针对给定的数据集，对其中的任意一个数据点，如果在其局部邻域内的点都很密集，那么认为此数据点为正常数据点，而离群点则是距离正常数据点最近邻的点都比较远的数据点

LOF:
表示点p的邻域点Nk(p)Nk(p)的局部可达密度与点p的局部可达密度之比的平均数。 
如果这个比值越接近1，说明p的其邻域点密度差不多，p可能和邻域同属一簇；如果这个比值越小于1，说明p的密度高于其邻域点密度，p为密集点；如果这个比值越大于1，说明p的密度小于其邻域点密度，p越可能是异常点。 